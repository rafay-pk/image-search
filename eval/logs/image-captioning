C:\Users\Rafay\repos\image-search\venv\Scripts\python.exe C:\Users\Rafay\repos\image-search\eval\image-captioning-eval.py
CSV file converted to Python dictionary successfully.
BLEU: Computed Scores for 8091 generated captions with a mean score of 0.2821315990591425
METEOR: Computed Scores for 8091 generated captions with a mean score of 0.40141343136234225
Parsing reference captions
Initiating Stanford parsing pipeline
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize
[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse
[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ...
done [0.2 sec].
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma
[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner
Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.3 sec].
Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.3 sec].
Threads( StanfordCoreNLP ) [25.185 seconds]
Parsing test captions
Threads( StanfordCoreNLP ) [2.103 seconds]
SPICE evaluation took: 34.47 s
CIDER: Computed Scores for 8091 generated captions with a mean score of 0.44710968870699846
SPICE: Computed Scores for 8091 generated captions with a mean score of 0.14036738130356877

Process finished with exit code 0
